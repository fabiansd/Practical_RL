{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb.\n",
      "env: DISPLAY=: 1\n"
     ]
    }
   ],
   "source": [
    "# In Google Colab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY = : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEkBJREFUeJzt3X+s31ddx/Hny3VsCGg3dm1qf9gpVTKMdPM6tkDM3IJu09iZKNk0sJAlF5ORQCTqpolC4hJNlClRF6sbFIOMOcA1yxRHWUL4g40WSmlXJhfo0jbd2sE2QOK04+0f93R87W57v/d+77e39/h8JJ98P5/zOZ/P95ztm9f93HPP6TdVhSSpPz+w1A2QJI2HAS9JnTLgJalTBrwkdcqAl6ROGfCS1KmxBXySq5M8lmQ6yS3jeh9J0uwyjnnwSc4C/gN4I3AQ+BxwQ1U9uuhvJkma1bie4C8Fpqvqa1X138DdwOYxvZckaRYrxnTfNcCBgeODwOtOVvmCCy6oDRs2jKkpkrT87N+/n6eeeiqj3GNcAT+nJFPAFMD69evZsWPHUjVFks44k5OTI99jXEM0h4B1A8drW9kLqmpLVU1W1eTExMSYmiFJ/3+NK+A/B2xMcmGSlwDXA9vG9F6SpFmMZYimqo4leTvwCeAs4K6q2juO95IkzW5sY/BV9QDwwLjuL0k6NVeySlKnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnq1Ehf2ZdkP/Bt4HngWFVNJjkf+AiwAdgPvKmqnh6tmZKk+VqMJ/hfqKpNVTXZjm8BtlfVRmB7O5YknWbjGKLZDGxt+1uB68bwHpKkOYwa8AX8e5KdSaZa2aqqOtz2nwBWjfgekqQFGGkMHnhDVR1K8iPAg0m+PHiyqipJzXZh+4EwBbB+/foRmyFJOtFIT/BVdai9HgE+DlwKPJlkNUB7PXKSa7dU1WRVTU5MTIzSDEnSLBYc8EleluQVx/eBXwT2ANuAG1u1G4H7Rm2kJGn+RhmiWQV8PMnx+/xTVf1bks8B9yS5CXgceNPozZQkzdeCA76qvga8dpbybwBXjdIoSdLoXMkqSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdWrOgE9yV5IjSfYMlJ2f5MEkX2mv57XyJHlfkukku5NcMs7GS5JObpgn+A8AV59Qdguwvao2AtvbMcA1wMa2TQF3LE4zJUnzNWfAV9WngW+eULwZ2Nr2twLXDZR/sGZ8FliZZPViNVaSNLyFjsGvqqrDbf8JYFXbXwMcGKh3sJW9SJKpJDuS7Dh69OgCmyFJOpmR/8haVQXUAq7bUlWTVTU5MTExajMkSSdYaMA/eXzopb0eaeWHgHUD9da2MknSabbQgN8G3Nj2bwTuGyh/S5tNcxnw7MBQjiTpNFoxV4UkHwauAC5IchD4Y+BPgXuS3AQ8DrypVX8AuBaYBr4LvHUMbZYkDWHOgK+qG05y6qpZ6hZw86iNkiSNzpWsktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6NWfAJ7kryZEkewbK3p3kUJJdbbt24NytSaaTPJbkl8bVcEnSqQ3zBP8B4OpZym+vqk1tewAgyUXA9cBr2jV/m+SsxWqsJGl4cwZ8VX0a+OaQ99sM3F1Vz1XV14Fp4NIR2idJWqBRxuDfnmR3G8I5r5WtAQ4M1DnYyl4kyVSSHUl2HD16dIRmSJJms9CAvwP4CWATcBj4i/neoKq2VNVkVU1OTEwssBmSpJNZUMBX1ZNV9XxVfQ/4e74/DHMIWDdQdW0rkySdZgsK+CSrBw5/DTg+w2YbcH2Sc5JcCGwEHhmtiZKkhVgxV4UkHwauAC5IchD4Y+CKJJuAAvYDbwOoqr1J7gEeBY4BN1fV8+NpuiTpVOYM+Kq6YZbiO09R/zbgtlEaJUkanStZJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqfmnCYp9Wznlre9qOxnp/5uCVoiLT6f4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE7NGfBJ1iV5KMmjSfYmeUcrPz/Jg0m+0l7Pa+VJ8r4k00l2J7lk3J2QJL3YME/wx4B3VdVFwGXAzUkuAm4BtlfVRmB7Owa4BtjYtingjkVvtSRpTnMGfFUdrqrPt/1vA/uANcBmYGurthW4ru1vBj5YMz4LrEyyetFbLkk6pXmNwSfZAFwMPAysqqrD7dQTwKq2vwY4MHDZwVZ24r2mkuxIsuPo0aPzbLYkaS5DB3ySlwMfBd5ZVd8aPFdVBdR83riqtlTVZFVNTkxMzOdSSdIQhgr4JGczE+4fqqqPteInjw+9tNcjrfwQsG7g8rWtTJJ0Gg0ziybAncC+qnrvwKltwI1t/0bgvoHyt7TZNJcBzw4M5UiSTpNhvrLv9cCbgS8l2dXK/gD4U+CeJDcBjwNvauceAK4FpoHvAm9d1BZLkoYyZ8BX1WeAnOT0VbPUL+DmEdslSRqRK1klqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHVqmC/dXpfkoSSPJtmb5B2t/N1JDiXZ1bZrB665Ncl0kseS/NI4OyBJmt0wX7p9DHhXVX0+ySuAnUkebOdur6o/H6yc5CLgeuA1wI8Cn0zyk1X1/GI2XJJ0anM+wVfV4ar6fNv/NrAPWHOKSzYDd1fVc1X1dWAauHQxGitJGt68xuCTbAAuBh5uRW9PsjvJXUnOa2VrgAMDlx3k1D8QJEljMHTAJ3k58FHgnVX1LeAO4CeATcBh4C/m88ZJppLsSLLj6NGj87lUkjSEoQI+ydnMhPuHqupjAFX1ZFU9X1XfA/6e7w/DHALWDVy+tpX9H1W1paomq2pyYmJilD5IkmYxzCyaAHcC+6rqvQPlqweq/Rqwp+1vA65Pck6SC4GNwCOL12RJ0jCGmUXzeuDNwJeS7GplfwDckGQTUMB+4G0AVbU3yT3Ao8zMwLnZGTSSdPrNGfBV9Rkgs5x64BTX3AbcNkK7JEkjciWrJHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjplwEtSpwx4dSfJ0Ns4rpfOFAa8JHVqmC/8kLp2/+GpF/Z/ZfWWJWyJtLh8gtf/a4PhPtuxtJwZ8JLUqWG+dPvcJI8k+WKSvUne08ovTPJwkukkH0nyklZ+Tjuebuc3jLcLkqTZDPME/xxwZVW9FtgEXJ3kMuDPgNur6lXA08BNrf5NwNOt/PZWTzojnTjm7hi8ejLMl24X8J12eHbbCrgS+M1WvhV4N3AHsLntA9wL/HWStPtIZ5TJt20Bvh/q716ylkiLb6hZNEnOAnYCrwL+Bvgq8ExVHWtVDgJr2v4a4ABAVR1L8izwSuCpk91/586dzinWsuTnVmeyoQK+qp4HNiVZCXwcePWob5xkCpgCWL9+PY8//viot5SA0xu6/mKqcZmcnBz5HvOaRVNVzwAPAZcDK5Mc/wGxFjjU9g8B6wDa+R8GvjHLvbZU1WRVTU5MTCyw+ZKkkxlmFs1Ee3InyUuBNwL7mAn6X2/VbgTua/vb2jHt/Kccf5ek02+YIZrVwNY2Dv8DwD1VdX+SR4G7k/wJ8AXgzlb/TuAfk0wD3wSuH0O7JUlzGGYWzW7g4lnKvwZcOkv5fwG/sSitkyQtmCtZJalTBrwkdcqAl6RO+c8FqztO2pJm+AQvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR1yoCXpE4Z8JLUKQNekjo1zJdun5vkkSRfTLI3yXta+QeSfD3JrrZtauVJ8r4k00l2J7lk3J2QJL3YMP8e/HPAlVX1nSRnA59J8q/t3O9W1b0n1L8G2Ni21wF3tFdJ0mk05xN8zfhOOzy7baf6RoXNwAfbdZ8FViZZPXpTJUnzMdQYfJKzkuwCjgAPVtXD7dRtbRjm9iTntLI1wIGByw+2MknSaTRUwFfV81W1CVgLXJrkp4FbgVcDPwecD/z+fN44yVSSHUl2HD16dJ7NliTNZV6zaKrqGeAh4OqqOtyGYZ4D3g9c2qodAtYNXLa2lZ14ry1VNVlVkxMTEwtrvSTppIaZRTORZGXbfynwRuDLx8fVkwS4DtjTLtkGvKXNprkMeLaqDo+l9ZKkkxpmFs1qYGuSs5j5gXBPVd2f5FNJJoAAu4DfbvUfAK4FpoHvAm9d/GZLkuYyZ8BX1W7g4lnKrzxJ/QJuHr1pkqRRuJJVkjplwEtSpwx4SeqUAS9JnTLgJalTBrwkdcqAl6ROGfCS1CkDXpI6ZcBLUqcMeEnqlAEvSZ0y4CWpUwa8JHXKgJekThnwktQpA16SOmXAS1KnDHhJ6tTQAZ/krCRfSHJ/O74wycNJppN8JMlLWvk57Xi6nd8wnqZLkk5lPk/w7wD2DRz/GXB7Vb0KeBq4qZXfBDzdym9v9SRJp9lQAZ9kLfDLwD+04wBXAve2KluB69r+5nZMO39Vqy9JOo1WDFnvL4HfA17Rjl8JPFNVx9rxQWBN218DHACoqmNJnm31nxq8YZIpYKodPpdkz4J6cOa7gBP63ole+wX99s1+LS8/lmSqqrYs9AZzBnySXwGOVNXOJFcs9I1O1Bq9pb3HjqqaXKx7n0l67Vuv/YJ++2a/lp8kO2g5uRDDPMG/HvjVJNcC5wI/BPwVsDLJivYUvxY41OofAtYBB5OsAH4Y+MZCGyhJWpg5x+Cr6taqWltVG4DrgU9V1W8BDwG/3qrdCNzX9re1Y9r5T1VVLWqrJUlzGmUe/O8Dv5Nkmpkx9jtb+Z3AK1v57wC3DHGvBf8Ksgz02rde+wX99s1+LT8j9S0+XEtSn1zJKkmdWvKAT3J1ksfaytdhhnPOKEnuSnJkcJpnkvOTPJjkK+31vFaeJO9rfd2d5JKla/mpJVmX5KEkjybZm+QdrXxZ9y3JuUkeSfLF1q/3tPIuVmb3uuI8yf4kX0qyq80sWfafRYAkK5Pcm+TLSfYluXwx+7WkAZ/kLOBvgGuAi4Abkly0lG1agA8AV59Qdguwvao2Atv5/t8hrgE2tm0KuOM0tXEhjgHvqqqLgMuAm9v/m+Xet+eAK6vqtcAm4Ookl9HPyuyeV5z/QlVtGpgSudw/izAzI/HfqurVwGuZ+X+3eP2qqiXbgMuBTwwc3wrcupRtWmA/NgB7Bo4fA1a3/dXAY23/74AbZqt3pm/MzJJ6Y099A34Q+DzwOmYWyqxo5S98LoFPAJe3/RWtXpa67Sfpz9oWCFcC9wPpoV+tjfuBC04oW9afRWamkH/9xP/ui9mvpR6ieWHVazO4InY5W1VVh9v+E8Cqtr8s+9t+fb8YeJgO+taGMXYBR4AHga8y5Mps4PjK7DPR8RXn32vHQ68458zuF0AB/55kZ1sFD8v/s3ghcBR4fxtW+4ckL2MR+7XUAd+9mvlRu2ynKiV5OfBR4J1V9a3Bc8u1b1X1fFVtYuaJ91Lg1UvcpJFlYMX5UrdlTN5QVZcwM0xxc5KfHzy5TD+LK4BLgDuq6mLgPzlhWvmo/VrqgD++6vW4wRWxy9mTSVYDtNcjrXxZ9TfJ2cyE+4eq6mOtuIu+AVTVM8ws2LuctjK7nZptZTZn+Mrs4yvO9wN3MzNM88KK81ZnOfYLgKo61F6PAB9n5gfzcv8sHgQOVtXD7fheZgJ/0fq11AH/OWBj+0v/S5hZKbttidu0GAZX8564yvct7a/hlwHPDvwqdkZJEmYWre2rqvcOnFrWfUsykWRl238pM39X2McyX5ldHa84T/KyJK84vg/8IrCHZf5ZrKongANJfqoVXQU8ymL26wz4Q8O1wH8wMw76h0vdngW0/8PAYeB/mPmJfBMzY5nbga8AnwTOb3XDzKyhrwJfAiaXuv2n6NcbmPnVcDewq23XLve+AT8DfKH1aw/wR638x4FHgGngn4FzWvm57Xi6nf/xpe7DEH28Ari/l361PnyxbXuP58Ry/yy2tm4CdrTP478A5y1mv1zJKkmdWuohGknSmBjwktQpA16SOmXAS1KnDHhJ6pQBL0mdMuAlqVMGvCR16n8BrYh5yR9TTXoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 20, 10), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(30, 20, 10),\n",
    "    activation='tanh',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03761426 -0.04257394  0.00859629 -0.02776916]]\n",
      "\n",
      "[0.55930452 0.44069548]\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "print(s.reshape(1, -1))\n",
    "print()\n",
    "probs = agent.predict_proba(s.reshape(1, -1))[0,:]\n",
    "\n",
    "print(probs)\n",
    "\n",
    "assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba(s.reshape(1, -1))[0,:]\n",
    "\n",
    "        assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(n_actions, p=probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[-0.00329609  0.02513293 -0.04204917 -0.02301468]\n",
      " [-0.00279343 -0.16936156 -0.04250947  0.25611036]\n",
      " [-0.00618066 -0.36385161 -0.03738726  0.53508787]\n",
      " [-0.0134577  -0.55842843 -0.0266855   0.81575983]\n",
      " [-0.02462627 -0.36295145 -0.01037031  0.51480416]]\n",
      "actions: [0, 0, 0, 1, 0]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "    reward_threshold = np.percentile(rewards_batch, q=percentile)\n",
    "\n",
    "    elite_states = []\n",
    "    elite_actions = []\n",
    "    \n",
    "    for i in range(len(rewards_batch)):\n",
    "        if rewards_batch[i] >= reward_threshold:\n",
    "\n",
    "            for j in range(len(states_batch[i])):\n",
    "                elite_states.append(states_batch[i][j])\n",
    "                elite_actions.append(actions_batch[i][j])\n",
    "    \n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 887.407, threshold=1000.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! You may stop training now via KeyboardInterrupt.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0ec7fe82e730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-0ec7fe82e730>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-2d3d568a8861>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(agent, t_max)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# use agent to predict a vector of action probabilities for state :s:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"make sure probabilities are a vector (hint: np.reshape)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36m_warn_for_nonsequence\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENABLE_ARRAY_FUNCTION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 150\n",
    "percentile = 50\n",
    "log = []\n",
    "\n",
    "for i in range(150):\n",
    "    # generate new sessions\n",
    "    sessions = [ generate_session(agent, t_max=1000) for _ in range(n_sessions) ]\n",
    "    \n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile=percentile)\n",
    "\n",
    "    agent.partial_fit(elite_states, elite_actions)\n",
    "\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "sessions = [generate_session(agent) for _ in range(100)]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.1.58.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
    "    return probs\n",
    "\n",
    "plt.imshow(visualize_mountain_car(env, agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
